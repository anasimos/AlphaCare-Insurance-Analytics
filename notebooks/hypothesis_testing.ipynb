{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b8f9d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78218b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d563aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ../data\\MachineLearningRating_v3.txt with delimiter '|'. Shape: (1000098, 52)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnderwrittenCoverID</th>\n",
       "      <th>PolicyID</th>\n",
       "      <th>TransactionMonth</th>\n",
       "      <th>IsVATRegistered</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>LegalType</th>\n",
       "      <th>Title</th>\n",
       "      <th>Language</th>\n",
       "      <th>Bank</th>\n",
       "      <th>AccountType</th>\n",
       "      <th>...</th>\n",
       "      <th>ExcessSelected</th>\n",
       "      <th>CoverCategory</th>\n",
       "      <th>CoverType</th>\n",
       "      <th>CoverGroup</th>\n",
       "      <th>Section</th>\n",
       "      <th>Product</th>\n",
       "      <th>StatutoryClass</th>\n",
       "      <th>StatutoryRiskType</th>\n",
       "      <th>TotalPremium</th>\n",
       "      <th>TotalClaims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-03-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>21.929825</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>21.929825</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-07-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145255</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Metered Taxis - R2000</td>\n",
       "      <td>Own damage</td>\n",
       "      <td>Own Damage</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>512.848070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145255</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-07-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Mobility - Metered Taxis - R2000</td>\n",
       "      <td>Own damage</td>\n",
       "      <td>Own Damage</td>\n",
       "      <td>Comprehensive - Taxi</td>\n",
       "      <td>Motor Comprehensive</td>\n",
       "      <td>Mobility Metered Taxis: Monthly</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnderwrittenCoverID  PolicyID     TransactionMonth  IsVATRegistered  \\\n",
       "0               145249     12827  2015-03-01 00:00:00             True   \n",
       "1               145249     12827  2015-05-01 00:00:00             True   \n",
       "2               145249     12827  2015-07-01 00:00:00             True   \n",
       "3               145255     12827  2015-05-01 00:00:00             True   \n",
       "4               145255     12827  2015-07-01 00:00:00             True   \n",
       "\n",
       "  Citizenship          LegalType Title Language                 Bank  \\\n",
       "0              Close Corporation    Mr  English  First National Bank   \n",
       "1              Close Corporation    Mr  English  First National Bank   \n",
       "2              Close Corporation    Mr  English  First National Bank   \n",
       "3              Close Corporation    Mr  English  First National Bank   \n",
       "4              Close Corporation    Mr  English  First National Bank   \n",
       "\n",
       "       AccountType  ...                    ExcessSelected CoverCategory  \\\n",
       "0  Current account  ...             Mobility - Windscreen    Windscreen   \n",
       "1  Current account  ...             Mobility - Windscreen    Windscreen   \n",
       "2  Current account  ...             Mobility - Windscreen    Windscreen   \n",
       "3  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
       "4  Current account  ...  Mobility - Metered Taxis - R2000    Own damage   \n",
       "\n",
       "    CoverType            CoverGroup              Section  \\\n",
       "0  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
       "1  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
       "2  Windscreen  Comprehensive - Taxi  Motor Comprehensive   \n",
       "3  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
       "4  Own Damage  Comprehensive - Taxi  Motor Comprehensive   \n",
       "\n",
       "                           Product StatutoryClass StatutoryRiskType  \\\n",
       "0  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "1  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "2  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "3  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "4  Mobility Metered Taxis: Monthly     Commercial     IFRS Constant   \n",
       "\n",
       "   TotalPremium TotalClaims  \n",
       "0     21.929825         0.0  \n",
       "1     21.929825         0.0  \n",
       "2      0.000000         0.0  \n",
       "3    512.848070         0.0  \n",
       "4      0.000000         0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = os.path.join('../data', 'MachineLearningRating_v3.txt')\n",
    "\n",
    "\n",
    "def load_data(filepath, delimiter='|'):\n",
    "    \"\"\"\n",
    "    Loads the insurance claims data from a text file.\n",
    "    Handles potential initial loading errors and allows specifying a delimiter.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the data file (.txt).\n",
    "        delimiter (str): The character used to separate values in the file (e.g., ',', '\\t', ';').\n",
    "                         Defaults to pipe.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # pd.read_csv can read .txt files if the delimiter is correctly specified\n",
    "        df = pd.read_csv(\n",
    "            filepath,\n",
    "            delimiter=delimiter,\n",
    "            low_memory=False  # Add this option\n",
    "        )\n",
    "        print(f\"Data loaded successfully from {filepath} with delimiter '{delimiter}'. Shape: {df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}. Please ensure the data TXT is in the 'data' directory and named 'insurance_claims.txt'.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading data: {e}\\n\"\n",
    "              \"Please check if the delimiter is correct and the file format is consistent.\")\n",
    "        return None\n",
    "    \n",
    "df=load_data(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414555df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d252d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth',\n",
      "       'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language',\n",
      "       'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province',\n",
      "       'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode',\n",
      "       'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders',\n",
      "       'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors',\n",
      "       'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser',\n",
      "       'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff',\n",
      "       'Rebuilt', 'Converted', 'CrossBorder', 'NumberOfVehiclesInFleet',\n",
      "       'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm',\n",
      "       'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section',\n",
      "       'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium',\n",
      "       'TotalClaims'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "157abf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked: 'Margin' column successfully created.\n",
      "Data preprocessing for analysis complete. Added 'HadClaim', 'LossRatio', 'Margin'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnderwrittenCoverID</th>\n",
       "      <th>PolicyID</th>\n",
       "      <th>TransactionMonth</th>\n",
       "      <th>IsVATRegistered</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>LegalType</th>\n",
       "      <th>Title</th>\n",
       "      <th>Language</th>\n",
       "      <th>Bank</th>\n",
       "      <th>AccountType</th>\n",
       "      <th>...</th>\n",
       "      <th>StatutoryClass</th>\n",
       "      <th>StatutoryRiskType</th>\n",
       "      <th>TotalPremium</th>\n",
       "      <th>TotalClaims</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>TransactionYearMonth</th>\n",
       "      <th>TransactionMonth_dt</th>\n",
       "      <th>HadClaim</th>\n",
       "      <th>LossRatio</th>\n",
       "      <th>Margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-03-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>21.929825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>2015-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>21.929825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>2015-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145249</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-07-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145255</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>512.848070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>2015-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.848070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145255</td>\n",
       "      <td>12827</td>\n",
       "      <td>2015-07-01 00:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Close Corporation</td>\n",
       "      <td>Mr</td>\n",
       "      <td>English</td>\n",
       "      <td>First National Bank</td>\n",
       "      <td>Current account</td>\n",
       "      <td>...</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>IFRS Constant</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnderwrittenCoverID  PolicyID     TransactionMonth IsVATRegistered  \\\n",
       "0               145249     12827  2015-03-01 00:00:00            True   \n",
       "1               145249     12827  2015-05-01 00:00:00            True   \n",
       "2               145249     12827  2015-07-01 00:00:00            True   \n",
       "3               145255     12827  2015-05-01 00:00:00            True   \n",
       "4               145255     12827  2015-07-01 00:00:00            True   \n",
       "\n",
       "  Citizenship          LegalType Title Language                 Bank  \\\n",
       "0              Close Corporation    Mr  English  First National Bank   \n",
       "1              Close Corporation    Mr  English  First National Bank   \n",
       "2              Close Corporation    Mr  English  First National Bank   \n",
       "3              Close Corporation    Mr  English  First National Bank   \n",
       "4              Close Corporation    Mr  English  First National Bank   \n",
       "\n",
       "       AccountType  ... StatutoryClass StatutoryRiskType TotalPremium  \\\n",
       "0  Current account  ...     Commercial     IFRS Constant    21.929825   \n",
       "1  Current account  ...     Commercial     IFRS Constant    21.929825   \n",
       "2  Current account  ...     Commercial     IFRS Constant     0.000000   \n",
       "3  Current account  ...     Commercial     IFRS Constant   512.848070   \n",
       "4  Current account  ...     Commercial     IFRS Constant     0.000000   \n",
       "\n",
       "  TotalClaims TransactionDate TransactionYearMonth TransactionMonth_dt  \\\n",
       "0         0.0      2015-03-01              2015-03                 NaN   \n",
       "1         0.0      2015-05-01              2015-05                 NaN   \n",
       "2         0.0      2015-07-01              2015-07                 NaN   \n",
       "3         0.0      2015-05-01              2015-05                 NaN   \n",
       "4         0.0      2015-07-01              2015-07                 NaN   \n",
       "\n",
       "  HadClaim  LossRatio      Margin  \n",
       "0        0        0.0   21.929825  \n",
       "1        0        0.0   21.929825  \n",
       "2        0        0.0    0.000000  \n",
       "3        0        0.0  512.848070  \n",
       "4        0        0.0    0.000000  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data_for_analysis(df):\n",
    "    \"\"\"\n",
    "    Performs preprocessing steps: type conversions, NaN handling, and feature engineering.\n",
    "    This version is more robust for hypothesis testing and modeling.\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Convert 'TransactionMonth' to datetime objects\n",
    "    if 'TransactionMonth' in df_processed.columns:\n",
    "        df_processed['TransactionDate'] = pd.to_datetime(df_processed['TransactionMonth'], errors='coerce')\n",
    "        df_processed['TransactionYearMonth'] = df_processed['TransactionDate'].dt.to_period('M')\n",
    "        # Handle TransactionMonth which might be YYMM format\n",
    "        df_processed['TransactionMonth_dt'] = df_processed['TransactionDate'].astype(str).apply(\n",
    "            lambda x: pd.to_datetime(f'20{x[:2]}-{x[2:]}-01', errors='coerce') if len(x) == 4 else np.nan\n",
    "        )\n",
    "    else:\n",
    "        print(\"'TransactionDate' column not found. Skipping datetime conversion.\")\n",
    "\n",
    "    # Ensure numerical columns are numeric, coercing errors to NaN\n",
    "    numerical_cols = ['TotalPremium', 'TotalClaims', 'CustomValueEstimate', 'Cylinders',\n",
    "                      'cubiccapacity', 'kilowatts', 'NumberOfDoors', 'CapitalOutstanding',\n",
    "                      'NumberOfVehiclesInFleet', 'SumInsured', 'CalculatedPremiumPerTerm',\n",
    "                      'ExcessSelected', 'RegistrationYear']\n",
    "    for col in numerical_cols:\n",
    "        if col in df_processed.columns:\n",
    "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "        else:\n",
    "            print(f\"Warning: Numerical column '{col}' not found in DataFrame. Skipping processing for this column.\")\n",
    "\n",
    "\n",
    "    # --- IMPORTANT: Check for critical columns before creating 'HadClaim', 'LossRatio', 'Margin' ---\n",
    "    missing_critical_cols = []\n",
    "    if 'TotalPremium' not in df_processed.columns:\n",
    "        missing_critical_cols.append('TotalPremium')\n",
    "    if 'TotalClaims' not in df_processed.columns:\n",
    "        missing_critical_cols.append('TotalClaims')\n",
    "\n",
    "    if missing_critical_cols:\n",
    "        print(f\"Error: Missing critical columns for risk/profit analysis: {', '.join(missing_critical_cols)}. Cannot proceed with 'HadClaim', 'LossRatio', 'Margin' calculation.\")\n",
    "        # Return df_processed even if critical columns are missing, but subsequent calculations will fail\n",
    "        # This allows the script to continue for debugging purposes, but the tests will skip.\n",
    "        return df_processed\n",
    "\n",
    "    # Create 'HadClaim' binary variable: 1 if TotalClaims > 0, else 0\n",
    "    df_processed['HadClaim'] = (df_processed['TotalClaims'] > 0).astype(int)\n",
    "\n",
    "    # Calculate Loss Ratio (TotalClaims / TotalPremium)\n",
    "    # Handle cases where TotalPremium is 0 or NaN to avoid division errors\n",
    "    df_processed['LossRatio'] = np.where(\n",
    "        (df_processed['TotalPremium'].notnull()) & (df_processed['TotalPremium'] > 0),\n",
    "        df_processed['TotalClaims'] / df_processed['TotalPremium'],\n",
    "        0 # Assign 0 if premium is 0 or null, or handle as NaN if preferred\n",
    "    )\n",
    "\n",
    "    # Calculate Margin (TotalPremium - TotalClaims)\n",
    "    df_processed['Margin'] = df_processed['TotalPremium'] - df_processed['TotalClaims']\n",
    "    print(\"Checked: 'Margin' column successfully created.\")\n",
    "\n",
    "    # Convert object columns that should be categorical to 'category' dtype\n",
    "    categorical_cols = ['IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language',\n",
    "                        'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province',\n",
    "                        'ItemType', 'VehicleType', 'make', 'Model', 'bodytype', 'AlarmImmobiliser',\n",
    "                        'TrackingDevice', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted',\n",
    "                        'CrossBorder', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section',\n",
    "                        'Product', 'StatutoryClass', 'StatutoryRiskType', 'MainCrestaZone', 'SubCrestaZone']\n",
    "    for col in categorical_cols:\n",
    "        if col in df_processed.columns:\n",
    "            df_processed[col] = df_processed[col].astype('category')\n",
    "        else:\n",
    "            print(f\"Warning: Categorical column '{col}' not found in DataFrame. Skipping processing for this column.\")\n",
    "\n",
    "\n",
    "    # Convert PostalCode to string, fill NaNs if any\n",
    "    if 'PostalCode' in df_processed.columns:\n",
    "        df_processed['PostalCode'] = df_processed['PostalCode'].astype(str).fillna('UNKNOWN')\n",
    "    else:\n",
    "        print(\"Warning: 'PostalCode' column not found in DataFrame. Skipping processing for this column.\")\n",
    "\n",
    "    print(\"Data preprocessing for analysis complete. Added 'HadClaim', 'LossRatio', 'Margin'.\")\n",
    "    return df_processed\n",
    "\n",
    "\n",
    "prep_df=preprocess_data_for_analysis(df)\n",
    "prep_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc367e31",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdf3d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Metric Calculation Functions ---\n",
    "\n",
    "def calculate_claim_frequency(df_segment):\n",
    "    \"\"\"Calculates claim frequency for a given DataFrame segment.\"\"\"\n",
    "    if df_segment.empty:\n",
    "        return 0.0\n",
    "    return df_segment['HadClaim'].mean() # Mean of 0s and 1s gives the proportion\n",
    "\n",
    "def calculate_claim_severity(df_segment):\n",
    "    \"\"\"\n",
    "    Calculates claim severity for a given DataFrame segment (only for policies with claims).\n",
    "    Returns NaN if no claims or segment is empty.\n",
    "    \"\"\"\n",
    "    claims_df = df_segment[df_segment['TotalClaims'] > 0]\n",
    "    if claims_df.empty:\n",
    "        return np.nan\n",
    "    return claims_df['TotalClaims'].mean()\n",
    "\n",
    "def calculate_average_margin(df_segment):\n",
    "    \"\"\"Calculates the average margin for a given DataFrame segment.\"\"\"\n",
    "    if df_segment.empty:\n",
    "        return np.nan\n",
    "    return df_segment['Margin'].mean()\n",
    "\n",
    "# --- Statistical Testing Functions ---\n",
    "\n",
    "def perform_chi_squared_test(group1_counts, group2_counts, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs a Chi-squared test for independence between two groups' claim frequencies.\n",
    "    Args:\n",
    "        group1_counts (tuple): (count_claims_group1, total_policies_group1)\n",
    "        group2_counts (tuple): (count_claims_group2, total_policies_group2)\n",
    "        alpha (float): Significance level.\n",
    "    Returns:\n",
    "        tuple: (statistic, p_value, interpretation_string)\n",
    "    \"\"\"\n",
    "    # Create an observed frequency table for the chi-squared test\n",
    "    # Row 0: Claim, Row 1: No Claim\n",
    "    # Col 0: Group 1, Col 1: Group 2\n",
    "    observed = np.array([\n",
    "        [group1_counts[0], group2_counts[0]],\n",
    "        [group1_counts[1] - group1_counts[0], group2_counts[1] - group2_counts[0]]\n",
    "    ])\n",
    "\n",
    "    if np.any(observed < 5) and (np.min(observed.sum(axis=0)) < 30): # Check for small expected frequencies or small samples\n",
    "        # Fallback to Fisher's exact test if Chi-squared assumptions are violated\n",
    "        # However, for typical large datasets, chi-squared is generally robust.\n",
    "        # For simplicity, we proceed with chi-squared but acknowledge this edge case.\n",
    "        pass\n",
    "\n",
    "    chi2, p_value, _, _ = stats.chi2_contingency(observed)\n",
    "\n",
    "    interpretation = f\"Chi-squared statistic: {chi2:.3f}, P-value: {p_value:.3f}. \"\n",
    "    if p_value < alpha:\n",
    "        interpretation += f\"Reject H₀: There is a statistically significant difference in claim frequency (p < {alpha}).\"\n",
    "    else:\n",
    "        interpretation += f\"Fail to reject H₀: No statistically significant difference in claim frequency (p >= {alpha}).\"\n",
    "    return chi2, p_value, interpretation\n",
    "def perform_ttest(group1_data, group2_data, metric_name, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs an independent t-test on two groups' numerical data (e.g., Claim Severity, Margin).\n",
    "    Args:\n",
    "        group1_data (pd.Series): Data for the first group.\n",
    "        group2_data (pd.Series): Data for the second group.\n",
    "        metric_name (str): Name of the metric being tested (for reporting).\n",
    "        alpha (float): Significance level.\n",
    "    Returns:\n",
    "        tuple: (statistic, p_value, interpretation_string)\n",
    "    \"\"\"\n",
    "    # Remove NaNs before t-test\n",
    "    group1_data = group1_data.dropna()\n",
    "    group2_data = group2_data.dropna()\n",
    "\n",
    "    if len(group1_data) < 2 or len(group2_data) < 2: # Need at least 2 samples for a t-test\n",
    "        return np.nan, np.nan, f\"Insufficient data for t-test on {metric_name}. Group sizes: {len(group1_data)}, {len(group2_data)}.\"\n",
    "\n",
    "    # Perform independent t-test (assuming unequal variances for robustness: Welch's t-test)\n",
    "    t_statistic, p_value = stats.ttest_ind(group1_data, group2_data, equal_var=False)\n",
    "\n",
    "    interpretation = f\"T-statistic: {t_statistic:.3f}, P-value: {p_value:.3f}. \"\n",
    "    if p_value < alpha:\n",
    "        interpretation += f\"Reject H₀: There is a statistically significant difference in {metric_name} (p < {alpha}).\"\n",
    "    else:\n",
    "        interpretation += f\"Fail to reject H₀: No statistically significant difference in {metric_name} (p >= {alpha}).\"\n",
    "    return t_statistic, p_value, interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349365b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26dcaaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "      Starting A/B Hypothesis Testing      \n",
      "==================================================\n",
      "\n",
      "\n",
      "--- Hypothesis 1: No risk differences across provinces ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Perserverence\\AppData\\Local\\Temp\\ipykernel_26336\\1143745562.py:20: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  province_metrics = df.groupby('Province').agg(TotalPolicies=('PolicyID', 'nunique'),ClaimsCount=('HadClaim', 'sum'),TotalClaimsAmount=('TotalClaims', 'sum'),TotalPremiumAmount=('TotalPremium', 'sum')).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Gauteng (High Claim Freq) vs. Eastern Cape (Low Claim Freq)\n",
      "Claim Frequency for Gauteng: 0.0034\n",
      "Claim Frequency for Eastern Cape: 0.0016\n",
      "  Claim Frequency (Proportions Z-test - internally uses chi-squared logic for large samples): Chi-squared statistic: 24.969, P-value: 0.000. Reject H₀: There is a statistically significant difference in claim frequency (p < 0.05).\n",
      "  Business Insight: Risk (Claim Frequency) varies significantly by province. Gauteng likely requires higher premiums or targeted risk mitigation compared to Eastern Cape.\n",
      "Claim Severity for Gauteng: 22243.88\n",
      "Claim Severity for Eastern Cape: 27128.53\n",
      "  Claim Severity (T-test): T-statistic: -0.665, P-value: 0.509. Fail to reject H₀: No statistically significant difference in Claim Severity (p >= 0.05).\n",
      "Average Margin for Gauteng: -13.56\n",
      "Average Margin for Eastern Cape: 25.83\n",
      "  Average Margin (T-test): T-statistic: -2.817, P-value: 0.005. Reject H₀: There is a statistically significant difference in Average Margin (p < 0.05).\n",
      "  Business Insight: The average profit margin varies significantly between provinces, indicating a need for region-specific pricing adjustments.\n",
      "\n",
      "--- Hypothesis 2: No risk differences between zip codes ---\n",
      "Comparing Zip Code 2000 (High Claim Freq) vs. Zip Code 300 (Low Claim Freq)\n",
      "Claim Frequency for Zip 2000: 0.0036\n",
      "Claim Frequency for Zip 300: 0.0014\n",
      "  Claim Frequency (Proportions Z-test): Chi-squared statistic: 6.174, P-value: 0.013. Reject H₀: There is a statistically significant difference in claim frequency (p < 0.05).\n",
      "  Business Insight: Risk (Claim Frequency) varies significantly by zip code. Consider localized premium adjustments or marketing efforts for high-risk zip codes like 2000.\n",
      "Claim Severity for Zip 2000: 19196.41\n",
      "Claim Severity for Zip 300: 8080.42\n",
      "  Claim Severity (T-test): T-statistic: 1.965, P-value: 0.092. Fail to reject H₀: No statistically significant difference in Claim Severity (p >= 0.05).\n",
      "\n",
      "--- Hypothesis 3: No significant margin (profit) difference between zip codes ---\n",
      "Comparing Zip Code 300 (High Margin) vs. Zip Code 1863 (Low Margin)\n",
      "Average Margin for Zip 300: 45.78\n",
      "Average Margin for Zip 1863: -100.57\n",
      "  Average Margin (T-test): T-statistic: 3.360, P-value: 0.001. Reject H₀: There is a statistically significant difference in Average Margin (p < 0.05).\n",
      "  Business Insight: Profitability (margin) differs significantly between zip codes. Marketing efforts should target high-margin areas like 300, and pricing adjustments may be needed for low-margin areas like 1863.\n",
      "\n",
      "--- Hypothesis 4: No significant risk difference between Women and Men ---\n",
      "Claim Frequency for Men: 0.0022\n",
      "Claim Frequency for Women: 0.0021\n",
      "  Claim Frequency (Proportions Z-test): Chi-squared statistic: 0.004, P-value: 0.951. Fail to reject H₀: No statistically significant difference in claim frequency (p >= 0.05).\n",
      "Claim Severity for Men: 14858.55\n",
      "Claim Severity for Women: 17874.72\n",
      "  Claim Severity (T-test): T-statistic: -0.579, P-value: 0.568. Fail to reject H₀: No statistically significant difference in Claim Severity (p >= 0.05).\n",
      "Average Margin for Men: 4.28\n",
      "Average Margin for Women: 8.03\n",
      "  Average Margin (T-test): T-statistic: -0.251, P-value: 0.802. Fail to reject H₀: No statistically significant difference in Average Margin (p >= 0.05).\n",
      "\n",
      "==================================================\n",
      "      Hypothesis Testing Completed      \n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Hypothesis Testing Execution ---\n",
    "\n",
    "def run_hypothesis_tests(df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Executes all defined hypothesis tests and reports findings.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"      Starting A/B Hypothesis Testing      \")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # --- H₀ 1: No risk differences across provinces ---\n",
    "    print(\"\\n--- Hypothesis 1: No risk differences across provinces ---\")\n",
    "    # For provinces, we need to compare multiple groups. A simple A/B test would involve picking\n",
    "    # two provinces. For a more comprehensive analysis (beyond simple A/B), ANOVA might be used for\n",
    "    # means, and Chi-squared for proportions across multiple groups.\n",
    "    # Here, we'll pick the two provinces with the highest and lowest loss ratios from EDA.\n",
    "    # Or, we can compare a high-risk province against the rest.\n",
    "    \n",
    "    # First, calculate overall metrics per province to identify candidates for comparison\n",
    "    province_metrics = df.groupby('Province').agg(TotalPolicies=('PolicyID', 'nunique'),ClaimsCount=('HadClaim', 'sum'),TotalClaimsAmount=('TotalClaims', 'sum'),TotalPremiumAmount=('TotalPremium', 'sum')).reset_index()\n",
    "    province_metrics['ClaimFrequency'] = province_metrics['ClaimsCount'] / province_metrics['TotalPolicies']\n",
    "    province_metrics['ClaimSeverity'] = province_metrics.apply(lambda row: row['TotalClaimsAmount'] / row['ClaimsCount'] if row['ClaimsCount'] > 0 else np.nan,axis=1)\n",
    "    province_metrics['AvgMargin'] = (province_metrics['TotalPremiumAmount'] - province_metrics['TotalClaimsAmount']) / province_metrics['TotalPolicies']\n",
    "\n",
    "    # Filter out provinces with very few policies if they skew results\n",
    "    province_metrics = province_metrics[province_metrics['TotalPolicies'] > 100].sort_values('ClaimFrequency', ascending=False) # Example filter\n",
    "\n",
    "    if not province_metrics.empty:\n",
    "        # Select a \"high-risk\" and \"low-risk\" province based on claim frequency\n",
    "        province_high_freq = province_metrics.iloc[0]['Province'] if not province_metrics.empty else None\n",
    "        province_low_freq = province_metrics.iloc[-1]['Province'] if len(province_metrics) > 1 else None\n",
    "\n",
    "        if province_high_freq and province_low_freq and province_high_freq != province_low_freq:\n",
    "            print(f\"Comparing {province_high_freq} (High Claim Freq) vs. {province_low_freq} (Low Claim Freq)\")\n",
    "\n",
    "            df_prov_high = df[df['Province'] == province_high_freq].dropna(subset=['HadClaim', 'TotalClaims', 'TotalPremium'])\n",
    "            df_prov_low = df[df['Province'] == province_low_freq].dropna(subset=['HadClaim', 'TotalClaims', 'TotalPremium'])\n",
    "\n",
    "            if df_prov_high.empty or df_prov_low.empty:\n",
    "                print(\"Not enough data for province comparison after dropping NaNs.\")\n",
    "            else:\n",
    "                # Test Claim Frequency\n",
    "                count_high_freq_claim = df_prov_high['HadClaim'].sum()\n",
    "                total_high_freq_policies = len(df_prov_high)\n",
    "                count_low_freq_claim = df_prov_low['HadClaim'].sum()\n",
    "                total_low_freq_policies = len(df_prov_low)\n",
    "\n",
    "                print(f\"Claim Frequency for {province_high_freq}: {calculate_claim_frequency(df_prov_high):.4f}\")\n",
    "                print(f\"Claim Frequency for {province_low_freq}: {calculate_claim_frequency(df_prov_low):.4f}\")\n",
    "\n",
    "                chi2_stat, p_val_freq, interpretation_freq = perform_chi_squared_test(\n",
    "                    (count_high_freq_claim, total_high_freq_policies),\n",
    "                    (count_low_freq_claim, total_low_freq_policies), alpha\n",
    "                )\n",
    "                print(f\"  Claim Frequency (Proportions Z-test - internally uses chi-squared logic for large samples): {interpretation_freq}\")\n",
    "                if p_val_freq < alpha:\n",
    "                    print(f\"  Business Insight: Risk (Claim Frequency) varies significantly by province. {province_high_freq} likely requires higher premiums or targeted risk mitigation compared to {province_low_freq}.\")\n",
    "\n",
    "                # Test Claim Severity (only for policies with claims)\n",
    "                severity_high = df_prov_high[df_prov_high['HadClaim'] == 1]['TotalClaims']\n",
    "                severity_low = df_prov_low[df_prov_low['HadClaim'] == 1]['TotalClaims']\n",
    "                print(f\"Claim Severity for {province_high_freq}: {calculate_claim_severity(df_prov_high):.2f}\")\n",
    "                print(f\"Claim Severity for {province_low_freq}: {calculate_claim_severity(df_prov_low):.2f}\")\n",
    "\n",
    "                t_stat_severity, p_val_severity, interpretation_severity = perform_ttest(severity_high, severity_low, \"Claim Severity\", alpha)\n",
    "                print(f\"  Claim Severity (T-test): {interpretation_severity}\")\n",
    "                if p_val_severity < alpha and not np.isnan(p_val_severity):\n",
    "                    print(f\"  Business Insight: Claim severity also differs significantly. Focus on understanding factors driving higher claim costs in {province_high_freq}.\")\n",
    "\n",
    "                # Test Average Margin\n",
    "                margin_high = df_prov_high['Margin']\n",
    "                margin_low = df_prov_low['Margin']\n",
    "                print(f\"Average Margin for {province_high_freq}: {calculate_average_margin(df_prov_high):.2f}\")\n",
    "                print(f\"Average Margin for {province_low_freq}: {calculate_average_margin(df_prov_low):.2f}\")\n",
    "\n",
    "                t_stat_margin, p_val_margin, interpretation_margin = perform_ttest(margin_high, margin_low, \"Average Margin\", alpha)\n",
    "                print(f\"  Average Margin (T-test): {interpretation_margin}\")\n",
    "                if p_val_margin < alpha and not np.isnan(p_val_margin):\n",
    "                    print(f\"  Business Insight: The average profit margin varies significantly between provinces, indicating a need for region-specific pricing adjustments.\")\n",
    "        else:\n",
    "            print(\"Not enough distinct provinces with sufficient data to perform meaningful A/B comparison based on initial frequency sorting.\")\n",
    "    else:\n",
    "        print(\"No provinces with sufficient data to perform comparison.\")\n",
    "\n",
    "\n",
    "    # --- H₀ 2: No risk differences between zip codes ---\n",
    "    print(\"\\n--- Hypothesis 2: No risk differences between zip codes ---\")\n",
    "    # Due to the large number of zip codes, we cannot compare all pairs.\n",
    "    # Instead, we'll pick a few prominent zip codes (e.g., top N by policies)\n",
    "    # and compare their risk metrics against the overall average, or pick a high-risk vs low-risk zip.\n",
    "    # For demonstration, let's pick two zip codes with high number of policies and compare them.\n",
    "    \n",
    "    # Calculate metrics for each postal code\n",
    "    postal_code_metrics = df.groupby('PostalCode').agg(TotalPolicies=('PolicyID', 'nunique'),ClaimsCount=('HadClaim', 'sum'),TotalClaimsAmount=('TotalClaims', 'sum'),TotalPremiumAmount=('TotalPremium', 'sum')).reset_index()\n",
    "    postal_code_metrics['ClaimFrequency'] = postal_code_metrics['ClaimsCount'] / postal_code_metrics['TotalPolicies']\n",
    "    postal_code_metrics['ClaimSeverity'] = postal_code_metrics.apply(lambda row: row['TotalClaimsAmount'] / row['ClaimsCount'] if row['ClaimsCount'] > 0 else np.nan,axis=1)\n",
    "    postal_code_metrics['AvgMargin'] = (postal_code_metrics['TotalPremiumAmount'] - postal_code_metrics['TotalClaimsAmount']) / postal_code_metrics['TotalPolicies']\n",
    "\n",
    "    # Filter out zip codes with very few policies and sort by claim frequency for picking candidates\n",
    "    postal_code_metrics = postal_code_metrics[postal_code_metrics['TotalPolicies'] > 50].sort_values('ClaimFrequency', ascending=False) # Example filter\n",
    "\n",
    "    if len(postal_code_metrics) >= 2:\n",
    "        zip_high_freq = postal_code_metrics.iloc[0]['PostalCode']\n",
    "        zip_low_freq = postal_code_metrics.iloc[-1]['PostalCode']\n",
    "\n",
    "        print(f\"Comparing Zip Code {zip_high_freq} (High Claim Freq) vs. Zip Code {zip_low_freq} (Low Claim Freq)\")\n",
    "\n",
    "        df_zip_high = df[df['PostalCode'] == zip_high_freq].dropna(subset=['HadClaim', 'TotalClaims', 'TotalPremium'])\n",
    "        df_zip_low = df[df['PostalCode'] == zip_low_freq].dropna(subset=['HadClaim', 'TotalClaims', 'TotalPremium'])\n",
    "\n",
    "        if df_zip_high.empty or df_zip_low.empty:\n",
    "            print(\"Not enough data for zip code comparison after dropping NaNs.\")\n",
    "        else:\n",
    "            # Test Claim Frequency\n",
    "            count_high_zip_claim = df_zip_high['HadClaim'].sum()\n",
    "            total_high_zip_policies = len(df_zip_high)\n",
    "            count_low_zip_claim = df_zip_low['HadClaim'].sum()\n",
    "            total_low_zip_policies = len(df_zip_low)\n",
    "\n",
    "            print(f\"Claim Frequency for Zip {zip_high_freq}: {calculate_claim_frequency(df_zip_high):.4f}\")\n",
    "            print(f\"Claim Frequency for Zip {zip_low_freq}: {calculate_claim_frequency(df_zip_low):.4f}\")\n",
    "\n",
    "            chi2_zip_freq, p_val_zip_freq, interpretation_zip_freq = perform_chi_squared_test((count_high_zip_claim, total_high_zip_policies),(count_low_zip_claim, total_low_zip_policies), alpha)\n",
    "            print(f\"  Claim Frequency (Proportions Z-test): {interpretation_zip_freq}\")\n",
    "            if p_val_zip_freq < alpha:\n",
    "                print(f\"  Business Insight: Risk (Claim Frequency) varies significantly by zip code. Consider localized premium adjustments or marketing efforts for high-risk zip codes like {zip_high_freq}.\")\n",
    "\n",
    "            # Test Claim Severity\n",
    "            severity_zip_high = df_zip_high[df_zip_high['HadClaim'] == 1]['TotalClaims']\n",
    "            severity_zip_low = df_zip_low[df_zip_low['HadClaim'] == 1]['TotalClaims']\n",
    "            print(f\"Claim Severity for Zip {zip_high_freq}: {calculate_claim_severity(df_zip_high):.2f}\")\n",
    "            print(f\"Claim Severity for Zip {zip_low_freq}: {calculate_claim_severity(df_zip_low):.2f}\")\n",
    "\n",
    "            t_stat_zip_severity, p_val_zip_severity, interpretation_zip_severity = perform_ttest(\n",
    "                severity_zip_high, severity_zip_low, \"Claim Severity\", alpha\n",
    "            )\n",
    "            print(f\"  Claim Severity (T-test): {interpretation_zip_severity}\")\n",
    "            if p_val_zip_severity < alpha and not np.isnan(p_val_zip_severity):\n",
    "                print(f\"  Business Insight: Claim severity also differs significantly between zip codes, indicating varying cost implications for claims in different areas.\")\n",
    "    else:\n",
    "        print(\"Not enough distinct zip codes with sufficient data to perform meaningful A/B comparison.\")\n",
    "\n",
    "\n",
    "    # --- H₀ 3: No significant margin (profit) difference between zip codes ---\n",
    "    print(\"\\n--- Hypothesis 3: No significant margin (profit) difference between zip codes ---\")\n",
    "    if len(postal_code_metrics) >= 2:\n",
    "        # Re-using the same high/low frequency zips for margin comparison for consistency\n",
    "        # Or, you could sort by AvgMargin to pick highest/lowest margin zips\n",
    "        zip_high_margin = postal_code_metrics.sort_values('AvgMargin', ascending=False).iloc[0]['PostalCode']\n",
    "        zip_low_margin = postal_code_metrics.sort_values('AvgMargin', ascending=True).iloc[0]['PostalCode']\n",
    "\n",
    "        print(f\"Comparing Zip Code {zip_high_margin} (High Margin) vs. Zip Code {zip_low_margin} (Low Margin)\")\n",
    "\n",
    "        df_zip_high_margin = df[df['PostalCode'] == zip_high_margin].dropna(subset=['Margin'])\n",
    "        df_zip_low_margin = df[df['PostalCode'] == zip_low_margin].dropna(subset=['Margin'])\n",
    "\n",
    "        if df_zip_high_margin.empty or df_zip_low_margin.empty:\n",
    "            print(\"Not enough data for zip code margin comparison after dropping NaNs.\")\n",
    "        else:\n",
    "            margin_high_zip_data = df_zip_high_margin['Margin']\n",
    "            margin_low_zip_data = df_zip_low_margin['Margin']\n",
    "\n",
    "            print(f\"Average Margin for Zip {zip_high_margin}: {calculate_average_margin(df_zip_high_margin):.2f}\")\n",
    "            print(f\"Average Margin for Zip {zip_low_margin}: {calculate_average_margin(df_zip_low_margin):.2f}\")\n",
    "\n",
    "            t_stat_zip_margin, p_val_zip_margin, interpretation_zip_margin = perform_ttest(\n",
    "                margin_high_zip_data, margin_low_zip_data, \"Average Margin\", alpha\n",
    "            )\n",
    "            print(f\"  Average Margin (T-test): {interpretation_zip_margin}\")\n",
    "            if p_val_zip_margin < alpha and not np.isnan(p_val_zip_margin):\n",
    "                print(f\"  Business Insight: Profitability (margin) differs significantly between zip codes. Marketing efforts should target high-margin areas like {zip_high_margin}, and pricing adjustments may be needed for low-margin areas like {zip_low_margin}.\")\n",
    "    else:\n",
    "        print(\"Not enough distinct zip codes with sufficient data for margin comparison.\")\n",
    "\n",
    "\n",
    "    # --- H₀ 4: No significant risk difference between Women and Men ---\n",
    "    print(\"\\n--- Hypothesis 4: No significant risk difference between Women and Men ---\")\n",
    "    df_gender = df[df['Gender'].isin(['Male', 'Female'])].dropna(subset=['HadClaim', 'TotalClaims', 'TotalPremium'])\n",
    "\n",
    "    if df_gender.empty:\n",
    "        print(\"No valid 'Male' or 'Female' data available for gender comparison after dropping NaNs.\")\n",
    "    else:\n",
    "        df_men = df_gender[df_gender['Gender'] == 'Male']\n",
    "        df_women = df_gender[df_gender['Gender'] == 'Female']\n",
    "\n",
    "        if df_men.empty or df_women.empty:\n",
    "            print(\"Not enough data for both 'Male' and 'Female' groups after filtering.\")\n",
    "        else:\n",
    "            # Test Claim Frequency\n",
    "            count_men_claim = df_men['HadClaim'].sum()\n",
    "            total_men_policies = len(df_men)\n",
    "            count_women_claim = df_women['HadClaim'].sum()\n",
    "            total_women_policies = len(df_women)\n",
    "\n",
    "            print(f\"Claim Frequency for Men: {calculate_claim_frequency(df_men):.4f}\")\n",
    "            print(f\"Claim Frequency for Women: {calculate_claim_frequency(df_women):.4f}\")\n",
    "\n",
    "            chi2_gender_freq, p_val_gender_freq, interpretation_gender_freq = perform_chi_squared_test(\n",
    "                (count_men_claim, total_men_policies),\n",
    "                (count_women_claim, total_women_policies), alpha\n",
    "            )\n",
    "            print(f\"  Claim Frequency (Proportions Z-test): {interpretation_gender_freq}\")\n",
    "            if p_val_gender_freq < alpha:\n",
    "                gender_with_higher_freq = \"Men\" if calculate_claim_frequency(df_men) > calculate_claim_frequency(df_women) else \"Women\"\n",
    "                print(f\"  Business Insight: There is a statistically significant difference in claim frequency between genders. {gender_with_higher_freq} show a different claim likelihood.\")\n",
    "\n",
    "            # Test Claim Severity (only for policies with claims)\n",
    "            severity_men = df_men[df_men['HadClaim'] == 1]['TotalClaims']\n",
    "            severity_women = df_women[df_women['HadClaim'] == 1]['TotalClaims']\n",
    "\n",
    "            print(f\"Claim Severity for Men: {calculate_claim_severity(df_men):.2f}\")\n",
    "            print(f\"Claim Severity for Women: {calculate_claim_severity(df_women):.2f}\")\n",
    "\n",
    "            t_stat_gender_severity, p_val_gender_severity, interpretation_gender_severity = perform_ttest(\n",
    "                severity_men, severity_women, \"Claim Severity\", alpha\n",
    "            )\n",
    "            print(f\"  Claim Severity (T-test): {interpretation_gender_severity}\")\n",
    "            if p_val_gender_severity < alpha and not np.isnan(p_val_gender_severity):\n",
    "                gender_with_higher_severity = \"Men\" if calculate_claim_severity(df_men) > calculate_claim_severity(df_women) else \"Women\"\n",
    "                print(f\"  Business Insight: Claim severity also differs significantly by gender, implying varying financial impact for claims based on gender.\")\n",
    "\n",
    "            # Test Average Margin\n",
    "            margin_men = df_men['Margin']\n",
    "            margin_women = df_women['Margin']\n",
    "\n",
    "            print(f\"Average Margin for Men: {calculate_average_margin(df_men):.2f}\")\n",
    "            print(f\"Average Margin for Women: {calculate_average_margin(df_women):.2f}\")\n",
    "\n",
    "            t_stat_gender_margin, p_val_gender_margin, interpretation_gender_margin = perform_ttest(\n",
    "                margin_men, margin_women, \"Average Margin\", alpha\n",
    "            )\n",
    "            print(f\"  Average Margin (T-test): {interpretation_gender_margin}\")\n",
    "            if p_val_gender_margin < alpha and not np.isnan(p_val_gender_margin):\n",
    "                gender_with_higher_margin = \"Men\" if calculate_average_margin(df_men) > calculate_average_margin(df_women) else \"Women\"\n",
    "                print(f\"  Business Insight: The average margin varies significantly between genders, suggesting gender-specific adjustments to premium or marketing could optimize profitability.\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"      Hypothesis Testing Completed      \")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "prep_df.head()  # Display the first few rows of the preprocessed DataFrame\n",
    "run_hypothesis_tests(prep_df, alpha=0.05)  # Execute the hypothesis tests\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
